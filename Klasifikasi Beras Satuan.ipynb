{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Klasifikasi Beras Satuan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6JoE4rdE9ae",
        "colab_type": "text"
      },
      "source": [
        "# Klasifikasi Jenis Beras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "# **Mengambil Dataset dari Google Grive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSYC1mrZ3LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEDzMpi9aTqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/Klasifikasi Beras Satuan.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9hD24Q7uaMn",
        "colab_type": "text"
      },
      "source": [
        "# **Mengambil Dataset dari Github**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_aICNeDuobz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install subversion > /dev/null\n",
        "\n",
        "!svn export https://github.com/Vidi005/Klasifikasi-Beras-Satuan/trunk/data > /dev/null\n",
        "!svn export https://github.com/Vidi005/Klasifikasi-Beras-Satuan/trunk/utils > /dev/null\n",
        "!svn export https://github.com/Vidi005/Klasifikasi-Beras-Satuan/trunk/Klasifikasi-Beras-Satuan.ipynb > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxlu9J0UFEbb",
        "colab_type": "text"
      },
      "source": [
        "## Persiapan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNqEeYHZIj7W",
        "colab_type": "text"
      },
      "source": [
        "How will you classify the bellow two images?\n",
        "\n",
        "![1rice](https://github.com/totti0223/deep_learning_for_biologists_with_keras/raw/master/assets/11.jpg) Ukuran beras pendek\n",
        "\n",
        "![2rice](https://github.com/totti0223/deep_learning_for_biologists_with_keras/raw/master/assets/141.jpg) Ukuran beras sedang\n",
        "\n",
        "\n",
        "In this tutorial, we will construct a classifier in 3 ways, giving you a rough implementation of how deep learning (step 3) can ignore the manual feature extraction we had to do (step 1 and 2). Although you may notice that the classification task is two easy that step 1 or step 2 is sufficient, will compare all steps for understanding.\n",
        "\n",
        "Step 1. Manual Classsification by Conventional Approach\n",
        "\n",
        "Step 2. Support Vector Machine based Classification\n",
        "\n",
        "Step 3. Convolutional Neural Network based Classification\n",
        "\n",
        "click the run button in each cell from the top to bottom and everything should run fine.\n",
        "if you don't want to see the results beforehand, click \"edit\" and select \"delete all the output of the cells\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdqTISDXFI9q",
        "colab_type": "text"
      },
      "source": [
        "## Memasukan Fungsi Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv_CFDFPE2BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import math, os, sys\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "from scipy import ndimage\n",
        "\n",
        "from skimage import measure, morphology\n",
        "from skimage.io import imsave, imread\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQptkk_24tvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#functions to assist visualizations\n",
        "\n",
        "#confusion matrix drawing function provided by sklearn\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    #code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    \"\"\"Create a mesh of points to plot in\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x: data to base x-axis meshgrid on\n",
        "    y: data to base y-axis meshgrid on\n",
        "    h: stepsize for meshgrid, optional\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    xx, yy : ndarray\n",
        "    #code from https://scikit-learn.org/stable/auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py\n",
        "    \"\"\"\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "\n",
        "def plot_contours(clf, xx, yy, **params):\n",
        "    \"\"\"Plot the decision boundaries for a classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ax: matplotlib axes object\n",
        "    clf: a classifier\n",
        "    xx: meshgrid ndarray\n",
        "    yy: meshgrid ndarray\n",
        "    params: dictionary of params to pass to contourf, optional\n",
        "    \"\"\"\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = plt.contourf(xx, yy, Z, **params)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_I6ZZ6HKvsV",
        "colab_type": "text"
      },
      "source": [
        "## Mengimpor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_oxMl_MLoQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this command below see inspects part of the files which have been downloaded from the cell above\n",
        "!ls data/image\n",
        "!ls data/image/train\n",
        "!ls data/image/train/pendek\n",
        "!ls data/image/train/sedang"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AXVWZgTPGYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let's visualize a single file\n",
        "image = imread(\"data/image/train/pendek/C1.jpg\")\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNV81ptRQD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lets load everything into memory first\n",
        "\n",
        "#load training dataset\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for root, dirs, files in os.walk(\"data/image/train\"):\n",
        "    files = [x for x in files if x.endswith(\".jpg\")]\n",
        "    for file in files:\n",
        "        image_path = os.path.join(root, file)\n",
        "        \n",
        "        image = imread(image_path)/255.\n",
        "        image = resize(image,(32,32))\n",
        "        X_train.append(image)        \n",
        "        category = os.path.split(root)[-1]\n",
        "        if category == \"pendek\":\n",
        "            y_train.append(0)\n",
        "        else:\n",
        "            y_train.append(1)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "\n",
        "#load test dataset\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for root, dirs, files in os.walk(\"data/image/test\"):\n",
        "    files = [x for x in files if x.endswith(\".jpg\")]\n",
        "    for file in files:\n",
        "        image_path = os.path.join(root, file)\n",
        "        \n",
        "        image = imread(image_path)/255.\n",
        "        image = resize(image,(32,32))\n",
        "        X_test.append(image)        \n",
        "        category = os.path.split(root)[-1]\n",
        "        if category == \"pendek\":\n",
        "            y_test.append(0)\n",
        "        else:\n",
        "            y_test.append(1)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(\"train dataset shape is:\", X_train.shape,y_train.shape)\n",
        "print(\"test dataset shape is:\", X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OGcB_v0x_Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
        "\n",
        "#randomly show several images from the training dataset\n",
        "index = np.random.randint(0,X_train.shape[0],size=9)\n",
        "\n",
        "for i, idx  in enumerate(index):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    \n",
        "    if y_train[idx] == 0:\n",
        "        label = \"pendek\"\n",
        "    else:\n",
        "        label = \"sedang\"\n",
        "    plt.title(label)\n",
        "    plt.imshow(X_train[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnx3mVnBkBPJ",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 Manual Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUFKmeIHmJm4",
        "colab_type": "text"
      },
      "source": [
        "Lets manually define the feature for classification. In this case, simply binarizing the image, extracting the area size of each image and then defining a threshold will do well. All of the image transformation and area measuring can be done with the functions of skimage and scipy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xW8efuFNJ2iL",
        "colab": {}
      },
      "source": [
        "#Let's try it for one image\n",
        "image = X_train[0]\n",
        "\n",
        "#the original image\n",
        "print(image.shape)\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(image)\n",
        "plt.title(\"Gambar ORI\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on8SXqeyqn6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gray conversion\n",
        "gray = rgb2gray(image)\n",
        "print(gray.shape)\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(gray, cmap=plt.cm.gray)\n",
        "plt.title(\"Terkonversi hitam putih\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHKRsea1qsEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#binary conversion\n",
        "threshold = threshold_otsu(gray)\n",
        "binary = gray > threshold\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(binary, cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUaXvXv7m_uk",
        "colab_type": "text"
      },
      "source": [
        "now that we have a nice binary image, we can isolate the region of rice seed which corresponds to the white region of the image above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErLnR9QmE2B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_im, nb_labels = ndimage.label(binary)\n",
        "regionprops = measure.regionprops(label_im, intensity_image=gray)\n",
        "regionprop = regionprops[0]\n",
        "\n",
        "print(\"area is\",regionprop.area)\n",
        "print(\"major axis length is\", regionprop.major_axis_length)\n",
        "print(\"minor axis length is\", regionprop.minor_axis_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi12D78UE2B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bundling the above into a function\n",
        "def quantify_area(image):\n",
        "    gray = rgb2gray(image)\n",
        "    threshold = threshold_otsu(gray)\n",
        "    binary = gray > threshold\n",
        "    label_im, nb_labels = ndimage.label(binary)\n",
        "    regionprops = measure.regionprops(label_im, intensity_image=gray)\n",
        "    regionprop = regionprops[0]\n",
        "    area = regionprop.area\n",
        "    return area\n",
        "\n",
        "#test\n",
        "area = quantify_area(image)\n",
        "print(area)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcb0dZVu1wQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_area = []\n",
        "for image in X_train:\n",
        "    area = quantify_area(image)\n",
        "    X_train_area.append(area)\n",
        "\n",
        "X_test_area = []\n",
        "for image in X_test:\n",
        "    area = quantify_area(image)\n",
        "    X_test_area.append(area)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN-OpWAu-G0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the calculated data area value of training dataset\n",
        "\n",
        "plt.scatter(range(len(X_train_area)),X_train_area,c=y_train,cmap=\"jet\")\n",
        "plt.xlabel(\"gambar beras\")\n",
        "plt.ylabel(\"ukuran (px)\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL5ADdJHFWCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define an area threshold that can seperate the two classes\n",
        "#must change from the default value or it won't seperate nicely.\n",
        "#run this code once and try the suitable value that can seperate blue and red with the horizontal lines\n",
        "area_threshold = 200\n",
        "\n",
        "\n",
        "#classify whether the image is a proper seed or a broken seed according to the area_threshold value\n",
        "train_y_pred = []\n",
        "for area in X_train_area:\n",
        "    if area > area_threshold:\n",
        "        train_y_pred.append(0)\n",
        "    else:\n",
        "        train_y_pred.append(1)\n",
        "        \n",
        "\n",
        "#plot scatter with threshold line\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.scatter(range(len(X_train_area)),X_train_area,c=y_train,cmap=plt.cm.coolwarm)\n",
        "plt.axhline(y=area_threshold)\n",
        "plt.title(\"biru: beras pendek, merah: beras sedang\")\n",
        "plt.show()\n",
        "\n",
        "#calculate confusion matrix\n",
        "cnf = confusion_matrix(y_train, train_y_pred)\n",
        "\n",
        "#confusion matrix in figure\n",
        "plt.figure(figsize=(3,3))\n",
        "plot_confusion_matrix(cnf, classes=[\"pendek\",\"sedang\"])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxXqorE_JARE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluate it with the test dataset\n",
        "test_y_pred = []\n",
        "for area in X_test_area:\n",
        "    if area > area_threshold:\n",
        "        test_y_pred.append(0)\n",
        "    else:\n",
        "        test_y_pred.append(1)\n",
        "        \n",
        "#plot scatter with threshold line\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.scatter(range(len(X_test_area)),X_test_area,c=y_test,cmap=plt.cm.coolwarm)\n",
        "plt.axhline(y=area_threshold)\n",
        "#plt.plot([100,0],[100,350],'k-',lw=2)\n",
        "plt.show()\n",
        "\n",
        "#calculate confusion matrix\n",
        "cnf = confusion_matrix(y_test, test_y_pred)\n",
        "\n",
        "#confusion matrix in figure\n",
        "plt.figure(figsize=(3,3))\n",
        "plot_confusion_matrix(cnf, classes=[\"pendek\",\"sedang\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqsUKwkRR2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build a classifier\n",
        "\n",
        "def manual_classifier(image,area_threshold):\n",
        "    gray = rgb2gray(image)\n",
        "    threshold = threshold_otsu(gray)\n",
        "    binary = gray > threshold\n",
        "    label_im, nb_labels = ndimage.label(binary)\n",
        "    regionprops = measure.regionprops(label_im, intensity_image=gray)\n",
        "    regionprop = regionprops[0]\n",
        "    area = regionprop.area\n",
        "    if area > area_threshold:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# get a image from test dataset #value must be lower than the size of the test dataset(20-1)\n",
        "n = 5\n",
        "image = X_test[n]\n",
        "label = y_test[n]\n",
        "area_threshold = 350\n",
        "prediction = manual_classifier(image,area_threshold)\n",
        "\n",
        "plt.imshow(image)\n",
        "print(\"correct label is: \",label)\n",
        "print(\"predicted label is: \",prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojDKRTbfXIhq",
        "colab_type": "text"
      },
      "source": [
        "# Step 2 Support Vector Machine Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ej1huDe3mGW",
        "colab_type": "text"
      },
      "source": [
        "We will next use Support Vector Machine (SVM) for Classification. Since SVM uses data greater than two dimension (features), we will add another metrics, major_axis_length of the region of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okr4TKP135If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quantify_mal(image):\n",
        "    gray = rgb2gray(image)\n",
        "    threshold = threshold_otsu(gray)\n",
        "    binary = gray > threshold\n",
        "    label_im, nb_labels = ndimage.label(binary)\n",
        "    regionprops = measure.regionprops(label_im, intensity_image=gray)\n",
        "    regionprop = regionprops[0]\n",
        "    mal = regionprop.major_axis_length\n",
        "    return mal\n",
        "\n",
        "\n",
        "X_train_mal = []\n",
        "for image in X_train:\n",
        "    mal = quantify_mal(image)\n",
        "    X_train_mal.append(mal)\n",
        "\n",
        "X_test_mal = []\n",
        "for image in X_test:\n",
        "    mal = quantify_mal(image)\n",
        "    X_test_mal.append(mal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erMfs7dCXIIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape data for svm input\n",
        "X_train2 = np.array([[x,y] for x,y in zip(X_train_mal,X_train_area)])\n",
        "X_test2 = np.array([[x,y] for x,y in zip(X_test_mal,X_test_area)])\n",
        "#just concatenating the two data\n",
        "print(X_train2[:5,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS3LOjAv7B9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define linear support vector machine for defining the threshold\n",
        "clf=svm.SVC(kernel=\"linear\")\n",
        "#train the classifier\n",
        "clf.fit(X_train2,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSIISUYfjCre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx, yy = make_meshgrid(X_train2[:,0],X_train2[:,1],h=0.08)\n",
        "plot_contours(clf, xx, yy,\n",
        "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "plt.scatter(X_train2[:,0],X_train2[:,1],c=y_train,cmap=plt.cm.coolwarm)\n",
        "plt.title(\"svm classifier for train data\")\n",
        "plt.xlabel(\"major_axis_length (px)\")\n",
        "plt.ylabel(\"area (px)\")\n",
        "plt.show()\n",
        "\n",
        "#Coordinates in the red region are classified broken seeds, while blue as proper shaped seeds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDK1CKxW6epm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx, yy = make_meshgrid(X_test2[:,0],X_test2[:,1],h=0.08)\n",
        "plot_contours(clf, xx, yy,\n",
        "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "plt.scatter(X_test2[:,0],X_test2[:,1],c=y_test,cmap=plt.cm.coolwarm)\n",
        "plt.title(\"svm classifier for test data\")\n",
        "plt.xlabel(\"major_axis_length (px)\")\n",
        "plt.ylabel(\"area (px)\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLKSazz71lKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#construct a classifier function\n",
        "def svm_classifier(clf,image):\n",
        "    gray = rgb2gray(image)\n",
        "    threshold = threshold_otsu(gray)\n",
        "    binary = gray > threshold\n",
        "    label_im, nb_labels = ndimage.label(binary)\n",
        "    regionprops = measure.regionprops(label_im, intensity_image=gray)\n",
        "    regionprop = regionprops[0]\n",
        "    area = regionprop.area\n",
        "    result = clf.predict(np.array([1,area]).reshape(1, -1))\n",
        "    return result\n",
        "# get a image from test dataset #value must be lower than the size of the test dataset(20-1)\n",
        "n = 1\n",
        "image = X_test[n]\n",
        "label = y_test[n]\n",
        "prediction = svm_classifier(clf,image)\n",
        "\n",
        "plt.imshow(image)\n",
        "print(\"correct label is: \",label)\n",
        "print(\"predicted label is: \",prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MPDz6JD_L2B",
        "colab_type": "text"
      },
      "source": [
        "# Step 3 Seperating the two classes with Deep learning (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIloTpemjLI",
        "colab_type": "text"
      },
      "source": [
        "Finaly, we will use Convolutional Neural Network, a type of deep learning architecture that can handle images. By using CNN, we are freed from defining a suitable feature and only have to feed the images to the network. The CNN will find the most suitable features for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii2LX74sE2Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49atXcXNGdvk",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j4GLYyuD_ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train2 = to_categorical(y_train)\n",
        "X_train3, X_valid3, y_train3, y_valid3 = train_test_split(X_train, y_train2, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5kWA1jHA3XI",
        "colab_type": "text"
      },
      "source": [
        "## Model Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDhGQRAvA5Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    layers.Conv2D(16, (3,3), input_shape=(32,32,3),name=\"conv1\"),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPool2D((2,2),name=\"pool1\"),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(32, (3,3),name=\"conv2\"),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPool2D((2,2),name=\"pool2\"),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,name=\"fc1\"),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Dense(2,name=\"fc2\"),\n",
        "    layers.Activation(\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YUZJT7wDpHF",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ONTwfhBDrC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x = X_train3, y = y_train3, batch_size=32, epochs= 10,validation_data=(X_valid3,y_valid3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu4RfPQXJJWS",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Training Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr4T5jKSHiT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history[\"acc\"],label=\"train_accuracy\")\n",
        "plt.plot(history.history[\"val_acc\"],label=\"validation_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"],label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"],label=\"validation_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLmgPgJMwN5m",
        "colab_type": "text"
      },
      "source": [
        "## Use the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfzV_FsuvyIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train3.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RgBHC1fwacN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 35\n",
        "input_image = X_train3[n][np.newaxis,...]\n",
        "print(\"label is: \", y_train3[n])\n",
        "\n",
        "predictions = model.predict(input_image)\n",
        "print(\"prediction is\",predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NlIkTYKnMej",
        "colab_type": "text"
      },
      "source": [
        "See that we just input image and get the results, while step 1 and step 2 required to construct feature(s) by our self.\n",
        "This seed classification task was quite easy, but the complex the image gets, the harder to construct the most suitable feature gets.\n",
        "That is when CNN shows its power.\n",
        "See also the Yeast GFP protein localization tutorial for more complex image classification task."
      ]
    }
  ]
}